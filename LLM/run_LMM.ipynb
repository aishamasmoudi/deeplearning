{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HITId                                              tweet       sentiment  \\\n",
      "0      1  صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  hateful_normal   \n",
      "1      2  صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...       offensive   \n",
      "2      3  طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...       offensive   \n",
      "3      4  @user @user انا اوافقك بخصوص السوريين و العراق...          normal   \n",
      "4      5  هذه السعودية التي شعبها شعب الخيم و بول البعير...          normal   \n",
      "\n",
      "  directness                           annotator_sentiment  target       group  \n",
      "0   indirect                                         shock  gender  individual  \n",
      "1   indirect  anger_confusion_sadness_indifference_disgust   other       other  \n",
      "2   indirect                                  indifference   other  individual  \n",
      "3     direct                                  indifference  origin       other  \n",
      "4   indirect                                  indifference  origin       other  \n",
      "(18661, 7)\n"
     ]
    }
   ],
   "source": [
    "#dowlnoad the dataset\n",
    "data_load = load_dataset(\"nedjmaou/MLMA_hate_speech\")\n",
    "data_train = data_load[\"train\"]\n",
    "dataset = data_train.to_pandas()\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3353, 7)\n",
      "   HITId                                              tweet       sentiment  \\\n",
      "0      1  صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  hateful_normal   \n",
      "1      2  صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...       offensive   \n",
      "2      3  طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...       offensive   \n",
      "3      4  @user @user انا اوافقك بخصوص السوريين و العراق...          normal   \n",
      "4      5  هذه السعودية التي شعبها شعب الخيم و بول البعير...          normal   \n",
      "\n",
      "  directness                           annotator_sentiment  target       group  \n",
      "0   indirect                                         shock  gender  individual  \n",
      "1   indirect  anger_confusion_sadness_indifference_disgust   other       other  \n",
      "2   indirect                                  indifference   other  individual  \n",
      "3     direct                                  indifference  origin       other  \n",
      "4   indirect                                  indifference  origin       other  \n",
      "(5647, 7)\n",
      "   HITId                                              tweet  \\\n",
      "0      1             call sis im boy girl still faggot shut   \n",
      "1      2               @user @user legit nilas retarded idk   \n",
      "2      3                                   said retard @url   \n",
      "3      4  america another 8 years obama's ideology via h...   \n",
      "4      5                @user don... fucking made cry twat.   \n",
      "\n",
      "                                      sentiment directness  \\\n",
      "0                                     offensive   indirect   \n",
      "1                       offensive_disrespectful   indirect   \n",
      "2             fearful_abusive_offensive_hateful   indirect   \n",
      "3  fearful_abusive_hateful_disrespectful_normal   indirect   \n",
      "4                                     offensive   indirect   \n",
      "\n",
      "                annotator_sentiment      target          group  \n",
      "0                 confusion_disgust      origin            gay  \n",
      "1                   anger_confusion  disability  special_needs  \n",
      "2                 confusion_disgust  disability  special_needs  \n",
      "3  anger_fear_shock_sadness_disgust      origin          other  \n",
      "4                     shock_disgust      gender          women  \n",
      "(4014, 7)\n",
      "   HITId                                              tweet  sentiment  \\\n",
      "0      1  rt @user personnage ainsi q tte la clique gauc...    abusive   \n",
      "1      2  @user @user @user bah oui t'as raison l'autre ...  offensive   \n",
      "2      3  moi j'ai personne à qui m'adresser pour réclam...    hateful   \n",
      "3      4  @user @user c...est vrai que les anchois sont ...     normal   \n",
      "4      5            eh les renois faut se réveiller la @url     normal   \n",
      "\n",
      "  directness                   annotator_sentiment  target            group  \n",
      "0     direct                                 shock  origin            other  \n",
      "1   indirect                                 shock   other       individual  \n",
      "2     direct  anger_confusion_sadness_fear_disgust   other            women  \n",
      "3   indirect                          indifference   other            other  \n",
      "4     direct                               sadness  origin  african_descent  \n"
     ]
    }
   ],
   "source": [
    "#dataset separate by languages\n",
    "arab_path = \"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/ar_dataset.csv\"\n",
    "ar_dataset = pd.read_csv(arab_path)\n",
    "print(ar_dataset.shape)\n",
    "print(ar_dataset.head())\n",
    "\n",
    "\n",
    "en_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/en_dataset.csv\"\n",
    "en_dataset = pd.read_csv(en_path)\n",
    "print(en_dataset.shape)\n",
    "print(en_dataset.head())\n",
    "\n",
    "fr_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/fr_dataset.csv\"\n",
    "fr_dataset = pd.read_csv(fr_path)\n",
    "print(fr_dataset.shape)\n",
    "print(fr_dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    15603\n",
       "0     3058\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get binary data (ground truth)\n",
    "dataset['sentiment'].unique()\n",
    "dataset['sentiment'] = dataset['sentiment'].apply(lambda x: 0 if x=='normal'else 1)\n",
    "dataset['sentiment'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call sis im boy girl still faggot shut',\n",
       " '@user @user legit nilas retarded idk',\n",
       " 'said retard @url',\n",
       " \"america another 8 years obama's ideology via hillary we'd well way shithole country.\",\n",
       " '@user don... fucking made cry twat.',\n",
       " 'one wants 2 negro swan',\n",
       " \"@user @user @user hahaha. one trump's shithole countries?\",\n",
       " 'u juul ur faggot',\n",
       " '@user @user even called country shithole people shithole people. sad.',\n",
       " 'canadians never met seen associated person currently labelled retarded . plan @url']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the text data\n",
    "dataset['tweet']\n",
    "en_dataset['tweet'].head(10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt\n",
    "prompt=[{\"role\": \"system\", \"content\": \"Do you think these tweets are hate speech, offensive or normal speech. Try your best even if we do not have context. Display the reasult as 0 (Normal), 1 (offensive), 2 (hate) list.\"},\n",
    "        #{\"role\": \"system\", \"content\": \"classify tweets as hate speech or normal speech. Store the result in a csv file in the LLM folder with either 0 or 1 as the label for each tweet\"},\n",
    "{\"role\": \"user\", \"content\":en_dataset['tweet'].head(100).tolist()},]\n",
    "#LLM initialization\n",
    "llm = Ollama(\n",
    "    model=\"llama3\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "llm.invoke( prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistake. I've re-checked and it seems that there is no CSV file in the LLM (Large Language Model) folder.\n",
      "\n",
      "As a next step, I would like to clarify what kind of data you have available to work with. Do you have any text files or datasets that contain the information you're trying to analyze? If so, please let me know and we can explore options for working with those files."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I apologize for the mistake. I've re-checked and it seems that there is no CSV file in the LLM (Large Language Model) folder.\\n\\nAs a next step, I would like to clarify what kind of data you have available to work with. Do you have any text files or datasets that contain the information you're trying to analyze? If so, please let me know and we can explore options for working with those files.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
