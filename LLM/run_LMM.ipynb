{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HITId                                              tweet       sentiment  \\\n",
      "0      1  صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  hateful_normal   \n",
      "1      2  صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...       offensive   \n",
      "2      3  طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...       offensive   \n",
      "3      4  @user @user انا اوافقك بخصوص السوريين و العراق...          normal   \n",
      "4      5  هذه السعودية التي شعبها شعب الخيم و بول البعير...          normal   \n",
      "\n",
      "  directness                           annotator_sentiment  target       group  \n",
      "0   indirect                                         shock  gender  individual  \n",
      "1   indirect  anger_confusion_sadness_indifference_disgust   other       other  \n",
      "2   indirect                                  indifference   other  individual  \n",
      "3     direct                                  indifference  origin       other  \n",
      "4   indirect                                  indifference  origin       other  \n",
      "(18661, 7)\n"
     ]
    }
   ],
   "source": [
    "#dowlnoad the dataset\n",
    "data_load = load_dataset(\"nedjmaou/MLMA_hate_speech\")\n",
    "data_train = data_load[\"train\"]\n",
    "dataset = data_train.to_pandas()\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 8)\n",
      "   HITId                                              tweet sentiment  \\\n",
      "0   1486                          بول البعير وعلاج السرطان!    normal   \n",
      "1   3194  الإسلام يتعامل مع القضايا قبل حصولها فيسعى لعل...    normal   \n",
      "2   1384  @user @user معلش سؤال..الكائن الابيض دا نوعه ا...    normal   \n",
      "3   1391  محاضرة التحرش والابتزاز كلية الحقوق والعلوم ال...    normal   \n",
      "4   1420  حرب شرسه على المرآه وحجابها من كل مكان الاعلام...    normal   \n",
      "\n",
      "  directness   annotator_sentiment    target  group  sentiment_binary  \n",
      "0   indirect  indifference_disgust     other  other                 1  \n",
      "1   indirect          indifference  religion  other                 1  \n",
      "2   indirect                 shock    origin  other                 1  \n",
      "3   indirect          indifference     other  other                 1  \n",
      "4     direct               sadness     other  women                 1  \n",
      "(600, 8)\n",
      "   HITId                                              tweet sentiment  \\\n",
      "0   5421                                         bad nigger    normal   \n",
      "1   2605  drop hard might next negro spiritual last new ...    normal   \n",
      "2   1269                      maybe called spic today  @url    normal   \n",
      "3   4375  -sighed. please stop saying ching chong. reall...    normal   \n",
      "4    935  les #migrants traversent la mer et trouvent le...    normal   \n",
      "\n",
      "  directness                         annotator_sentiment  target  \\\n",
      "0   indirect  anger_confusion_shock_indifference_disgust   other   \n",
      "1   indirect                               shock_disgust  origin   \n",
      "2   indirect                        indifference_disgust  origin   \n",
      "3   indirect                              confusion_fear  origin   \n",
      "4   indirect                               anger_sadness  origin   \n",
      "\n",
      "           group  sentiment_binary  \n",
      "0          other                 1  \n",
      "1  special_needs                 1  \n",
      "2       refugees                 1  \n",
      "3        muslims                 1  \n",
      "4          other                 1  \n",
      "(600, 8)\n",
      "   HITId                                              tweet sentiment  \\\n",
      "0    437  @user du coup pour l’attarde c’est celui qui é...    normal   \n",
      "1     64  @user @user @user mr simon vous ne pouvez just...    normal   \n",
      "2    125  les tutos en français sur youtube c’est insupp...    normal   \n",
      "3    750  @user pq y'a autant de rebeus qui tiennent ave...    normal   \n",
      "4    599  @user non à la dictature de la pensée non au t...    normal   \n",
      "\n",
      "  directness   annotator_sentiment  target          group  sentiment_binary  \n",
      "0     direct          indifference  origin  special_needs                 1  \n",
      "1   indirect          indifference   other          other                 1  \n",
      "2     direct                 shock  origin          other                 1  \n",
      "3   indirect  sadness_indifference  origin          arabs                 1  \n",
      "4   indirect               sadness   other          other                 1  \n"
     ]
    }
   ],
   "source": [
    "#dataset separate by languages\n",
    "arab_path = \"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/ar_dataset_600.csv\"\n",
    "ar_dataset = pd.read_csv(arab_path)\n",
    "print(ar_dataset.shape)\n",
    "print(ar_dataset.head())\n",
    "ar_dataset = ar_dataset.sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "en_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/en_dataset_600.csv\"\n",
    "en_dataset = pd.read_csv(en_path)\n",
    "print(en_dataset.shape)\n",
    "print(en_dataset.head())\n",
    "en_dataset = en_dataset.sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "fr_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/fr_dataset_600.csv\"\n",
    "fr_dataset = pd.read_csv(fr_path)\n",
    "print(fr_dataset.shape)\n",
    "print(fr_dataset.head())\n",
    "fr_dataset = fr_dataset.sample(frac=1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random shuffle\n",
    "en_dataset = en_dataset.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create binary datasets\n",
    "en_dataset_binary=en_dataset.copy()\n",
    "en_dataset_binary = en_dataset_binary[en_dataset_binary['sentiment_binary'].isin([2, 3])]\n",
    "en_dataset_binary['sentiment_binary'] = en_dataset_binary['sentiment_binary'].replace(2, 0)\n",
    "en_dataset_binary['sentiment_binary'] = en_dataset_binary['sentiment_binary'].replace(3, 1)\n",
    "\n",
    "ar_dataset_binary=ar_dataset.copy()\n",
    "ar_dataset_binary = ar_dataset_binary[ar_dataset_binary['sentiment_binary'].isin([2, 3])]\n",
    "ar_dataset_binary['sentiment_binary'] = ar_dataset_binary['sentiment_binary'].replace(2, 0)\n",
    "ar_dataset_binary['sentiment_binary'] = ar_dataset_binary['sentiment_binary'].replace(3, 1)\n",
    "\n",
    "fr_dataset_binary=fr_dataset.copy()\n",
    "fr_dataset_binary = fr_dataset_binary[fr_dataset_binary['sentiment_binary'].isin([2, 3])]\n",
    "fr_dataset_binary['sentiment_binary'] = fr_dataset_binary['sentiment_binary'].replace(2, 0)\n",
    "fr_dataset_binary['sentiment_binary'] = fr_dataset_binary['sentiment_binary'].replace(3, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 168/400 [02:04<02:51,  1.35it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'I cannot determine hatefulness without context. However, based on the tweet alone, I would rate it as 0 (Offensive).'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[0;32m---> 16\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     17\u001b[0m     predictions_concat\u001b[38;5;241m.\u001b[39mappend(predictions)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(predictions_concat))\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'I cannot determine hatefulness without context. However, based on the tweet alone, I would rate it as 0 (Offensive).'"
     ]
    }
   ],
   "source": [
    "#One by One\n",
    "\n",
    "used_data = en_dataset_binary\n",
    "predictions_concat=[]\n",
    "\n",
    "# Wrap range with tqdm\n",
    "for i in tqdm(range(used_data.shape[0])):\n",
    "    tweet = en_dataset['tweet'].iloc[i]\n",
    "    # prompt\n",
    "    prompt = [{\"role\": \"system\", \"content\": \"Do you think these tweets are hatefull speech or just offensive speech. Try your best even if we do not have context. Display the reasult as an integer of 0 (Offensive) or 1 (Hateful). Do not display anything else. Give an answer of this form even if you are not sure.\"},\n",
    "              #{\"role\": \"system\", \"content\": \"Do you think these tweets are hatefull speech, offensive or normal speech. Try your best to distinguish the 3 even if we do not have context. Display the reasult as an integer of 1 (Normal), 2(offensive) or 3 (Hateful). Do not display anything else, it is important that only the interger is displayed.\"},\n",
    "              {\"role\": \"user\", \"content\": tweet},]\n",
    "    # LLM initialization\n",
    "    llm = Ollama(model=\"llama3\")\n",
    "    predictions = llm.invoke(prompt)\n",
    "    predictions = int(predictions) \n",
    "    predictions_concat.append(predictions)\n",
    "\n",
    "print(len(predictions_concat))\n",
    "#add the predictions to the dataset\n",
    "used_data['predictions'] = predictions_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.382, F1: 0.318, Precision: 0.478, Recall: 0.382\n"
     ]
    }
   ],
   "source": [
    "#Metrics\n",
    "acc=accuracy_score(used_data['sentiment_binary'], used_data['predictions'])\n",
    "F1=f1_score(used_data['sentiment_binary'], used_data['predictions'], average='macro')\n",
    "Precision=precision_score(used_data['sentiment_binary'], used_data['predictions'], average='macro')\n",
    "Recall=recall_score(used_data['sentiment_binary'], used_data['predictions'], average='macro')\n",
    "print(f\"Accuracy: {acc:.3f}, F1: {F1:.3f}, Precision: {Precision:.3f}, Recall: {Recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentiment  sentiment_binary  predictions\n",
      "110     normal                 1            1\n",
      "419    hateful                 3            3\n",
      "565    hateful                 3            3\n",
      "77      normal                 1            2\n",
      "181     normal                 1            3\n",
      "..         ...               ...          ...\n",
      "71      normal                 1            3\n",
      "106     normal                 1            3\n",
      "270  offensive                 2            3\n",
      "435    hateful                 3            3\n",
      "102     normal                 1            3\n",
      "\n",
      "[600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(used_data[[ 'sentiment','sentiment_binary', 'predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110    1\n",
      "419    3\n",
      "565    3\n",
      "77     1\n",
      "181    1\n",
      "Name: sentiment_binary, dtype: int64\n",
      "(600, 8)\n"
     ]
    }
   ],
   "source": [
    "print(en_dataset['sentiment_binary'].head())\n",
    "print(en_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
