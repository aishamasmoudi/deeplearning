{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HITId                                              tweet       sentiment  \\\n",
      "0      1  صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  hateful_normal   \n",
      "1      2  صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...       offensive   \n",
      "2      3  طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...       offensive   \n",
      "3      4  @user @user انا اوافقك بخصوص السوريين و العراق...          normal   \n",
      "4      5  هذه السعودية التي شعبها شعب الخيم و بول البعير...          normal   \n",
      "\n",
      "  directness                           annotator_sentiment  target       group  \n",
      "0   indirect                                         shock  gender  individual  \n",
      "1   indirect  anger_confusion_sadness_indifference_disgust   other       other  \n",
      "2   indirect                                  indifference   other  individual  \n",
      "3     direct                                  indifference  origin       other  \n",
      "4   indirect                                  indifference  origin       other  \n",
      "(18661, 7)\n"
     ]
    }
   ],
   "source": [
    "#dowlnoad the dataset\n",
    "data_load = load_dataset(\"nedjmaou/MLMA_hate_speech\")\n",
    "data_train = data_load[\"train\"]\n",
    "dataset = data_train.to_pandas()\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3353, 7)\n",
      "   HITId                                              tweet       sentiment  \\\n",
      "0      1  صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  hateful_normal   \n",
      "1      2  صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...       offensive   \n",
      "2      3  طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...       offensive   \n",
      "3      4  @user @user انا اوافقك بخصوص السوريين و العراق...          normal   \n",
      "4      5  هذه السعودية التي شعبها شعب الخيم و بول البعير...          normal   \n",
      "\n",
      "  directness                           annotator_sentiment  target       group  \n",
      "0   indirect                                         shock  gender  individual  \n",
      "1   indirect  anger_confusion_sadness_indifference_disgust   other       other  \n",
      "2   indirect                                  indifference   other  individual  \n",
      "3     direct                                  indifference  origin       other  \n",
      "4   indirect                                  indifference  origin       other  \n",
      "(5647, 7)\n",
      "   HITId                                              tweet  \\\n",
      "0      1             call sis im boy girl still faggot shut   \n",
      "1      2               @user @user legit nilas retarded idk   \n",
      "2      3                                   said retard @url   \n",
      "3      4  america another 8 years obama's ideology via h...   \n",
      "4      5                @user don... fucking made cry twat.   \n",
      "\n",
      "                                      sentiment directness  \\\n",
      "0                                     offensive   indirect   \n",
      "1                       offensive_disrespectful   indirect   \n",
      "2             fearful_abusive_offensive_hateful   indirect   \n",
      "3  fearful_abusive_hateful_disrespectful_normal   indirect   \n",
      "4                                     offensive   indirect   \n",
      "\n",
      "                annotator_sentiment      target          group  \n",
      "0                 confusion_disgust      origin            gay  \n",
      "1                   anger_confusion  disability  special_needs  \n",
      "2                 confusion_disgust  disability  special_needs  \n",
      "3  anger_fear_shock_sadness_disgust      origin          other  \n",
      "4                     shock_disgust      gender          women  \n",
      "(4014, 7)\n",
      "   HITId                                              tweet  sentiment  \\\n",
      "0      1  rt @user personnage ainsi q tte la clique gauc...    abusive   \n",
      "1      2  @user @user @user bah oui t'as raison l'autre ...  offensive   \n",
      "2      3  moi j'ai personne à qui m'adresser pour réclam...    hateful   \n",
      "3      4  @user @user c...est vrai que les anchois sont ...     normal   \n",
      "4      5            eh les renois faut se réveiller la @url     normal   \n",
      "\n",
      "  directness                   annotator_sentiment  target            group  \n",
      "0     direct                                 shock  origin            other  \n",
      "1   indirect                                 shock   other       individual  \n",
      "2     direct  anger_confusion_sadness_fear_disgust   other            women  \n",
      "3   indirect                          indifference   other            other  \n",
      "4     direct                               sadness  origin  african_descent  \n"
     ]
    }
   ],
   "source": [
    "#dataset separate by languages\n",
    "arab_path = \"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/ar_dataset.csv\"\n",
    "ar_dataset = pd.read_csv(arab_path)\n",
    "print(ar_dataset.shape)\n",
    "print(ar_dataset.head())\n",
    "\n",
    "\n",
    "en_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/en_dataset.csv\"\n",
    "en_dataset = pd.read_csv(en_path)\n",
    "print(en_dataset.shape)\n",
    "print(en_dataset.head())\n",
    "\n",
    "fr_path=\"/Users/benoitmathey-doret/Documents/EPFL/MA2/DL/project/deeplearning/dataset/fr_dataset.csv\"\n",
    "fr_dataset = pd.read_csv(fr_path)\n",
    "print(fr_dataset.shape)\n",
    "print(fr_dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    15603\n",
       "0     3058\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get binary data (ground truth)\n",
    "dataset['sentiment'].unique()\n",
    "dataset['sentiment'] = dataset['sentiment'].apply(lambda x: 0 if x=='normal'else 1)\n",
    "dataset['sentiment'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:30<00:00,  1.33it/s]\n",
      "/var/folders/gm/941r48zd5qxcl4tb3v9q30440000gn/T/ipykernel_93745/2836036701.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  used_data['predictions'] = predictions_concat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>directness</th>\n",
       "      <th>annotator_sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>group</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>call sis im boy girl still faggot shut</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>gay</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user legit nilas retarded idk</td>\n",
       "      <td>offensive_disrespectful</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_confusion</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>said retard @url</td>\n",
       "      <td>fearful_abusive_offensive_hateful</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_disgust</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>america another 8 years obama's ideology via h...</td>\n",
       "      <td>fearful_abusive_hateful_disrespectful_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_fear_shock_sadness_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@user don... fucking made cry twat.</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>gender</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>one wants 2 negro swan</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>origin</td>\n",
       "      <td>left_wing_people</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user @user hahaha. one trump's shithole...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_sadness_indifference_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>u juul ur faggot</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_fear_indifference_sadness_disgust</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>@user @user even called country shithole peopl...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_fear_indifference_sadness_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>canadians never met seen associated person cur...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>sadness_indifference</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>@user @user south africa years come. keep supp...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>@user i'm oprah winfrey. oprah singing faggot</td>\n",
       "      <td>offensive</td>\n",
       "      <td>direct</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>individual</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>hahaha grow faggot @url</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>@user michael - live one 'shithole' countries ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>saturday everyone remember beer liquor never s...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_fear_shock_sadness_disgust</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>dope new gospel - lighter flick. soul beat. wi...</td>\n",
       "      <td>normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>@user queue fucking retarded makes everyone fe...</td>\n",
       "      <td>offensive_hateful</td>\n",
       "      <td>direct</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>@user mexican spic dora</td>\n",
       "      <td>hateful_disrespectful</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>shorty called faggot cause respond lmfaoooo</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>@user ok maybe send finished</td>\n",
       "      <td>normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>@user cunt embarrassment club</td>\n",
       "      <td>hateful_disrespectful</td>\n",
       "      <td>indirect</td>\n",
       "      <td>sadness_shock_indifference_disgust</td>\n",
       "      <td>gender</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>wow watching documentary evidence sexual assau...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>@user que ce ne soit pas des burundais refugie...</td>\n",
       "      <td>hateful_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>dude i'm tired retarded</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>mongoloid ordered 9 dozen donuts 8 called back...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>direct</td>\n",
       "      <td>indifference_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>individual</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>also believes slaves immigrants. he's fool dis...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>origin</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>pretty sure employee philip green called 'bald...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3 people shot armed police officers dumb twat ...</td>\n",
       "      <td>abusive_offensive</td>\n",
       "      <td>direct</td>\n",
       "      <td>anger_disgust</td>\n",
       "      <td>gender</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>@user would honduras guatemala quality shithol...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>sadness_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>@user @user btw. allowed say shithole countrie...</td>\n",
       "      <td>normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>yepnnplus spic &amp;amp; span waxed &amp;amp; buffed: ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_disgust</td>\n",
       "      <td>origin</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>@user @user trump voice:nmy friend chinaman lo...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>confusion_indifference</td>\n",
       "      <td>origin</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>bitch retarded  hate @url</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>disability</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>@user migrants.7z</td>\n",
       "      <td>abusive_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_indifference</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>hetero guy: faggot bet wanna suck dick nnme: @url</td>\n",
       "      <td>offensive_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>indifference_disgust</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>@user fallait pad arriver en retard</td>\n",
       "      <td>abusive_offensive_hateful_disrespectful_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>indifference_disgust</td>\n",
       "      <td>disability</td>\n",
       "      <td>special_needs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>using word retard form great way make lose hug...</td>\n",
       "      <td>fearful_offensive_hateful_disrespectful_normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock_disgust</td>\n",
       "      <td>sexual_orientation</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>everyone knows feminazi's r lying gd teeth @us...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>indifference_disgust</td>\n",
       "      <td>other</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>@user care moral voters; want liberals illegal...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>indifference_disgust</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>@user still bitter cunt. much interest arsenal...</td>\n",
       "      <td>abusive_hateful</td>\n",
       "      <td>indirect</td>\n",
       "      <td>anger_sadness</td>\n",
       "      <td>gender</td>\n",
       "      <td>women</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HITId                                              tweet  \\\n",
       "0       1             call sis im boy girl still faggot shut   \n",
       "1       2               @user @user legit nilas retarded idk   \n",
       "2       3                                   said retard @url   \n",
       "3       4  america another 8 years obama's ideology via h...   \n",
       "4       5                @user don... fucking made cry twat.   \n",
       "5       6                             one wants 2 negro swan   \n",
       "6       7  @user @user @user hahaha. one trump's shithole...   \n",
       "7       8                                   u juul ur faggot   \n",
       "8       9  @user @user even called country shithole peopl...   \n",
       "9      10  canadians never met seen associated person cur...   \n",
       "10     11  @user @user south africa years come. keep supp...   \n",
       "11     12      @user i'm oprah winfrey. oprah singing faggot   \n",
       "12     13                            hahaha grow faggot @url   \n",
       "13     14  @user michael - live one 'shithole' countries ...   \n",
       "14     15  saturday everyone remember beer liquor never s...   \n",
       "15     16  dope new gospel - lighter flick. soul beat. wi...   \n",
       "16     17  @user queue fucking retarded makes everyone fe...   \n",
       "17     18                            @user mexican spic dora   \n",
       "18     19        shorty called faggot cause respond lmfaoooo   \n",
       "19     20                       @user ok maybe send finished   \n",
       "20     21                      @user cunt embarrassment club   \n",
       "21     22  wow watching documentary evidence sexual assau...   \n",
       "22     23  @user que ce ne soit pas des burundais refugie...   \n",
       "23     24                            dude i'm tired retarded   \n",
       "24     25  mongoloid ordered 9 dozen donuts 8 called back...   \n",
       "25     26  also believes slaves immigrants. he's fool dis...   \n",
       "26     27  pretty sure employee philip green called 'bald...   \n",
       "27     28  3 people shot armed police officers dumb twat ...   \n",
       "28     29  @user would honduras guatemala quality shithol...   \n",
       "29     30  @user @user btw. allowed say shithole countrie...   \n",
       "30     31  yepnnplus spic &amp; span waxed &amp; buffed: ...   \n",
       "31     32  @user @user trump voice:nmy friend chinaman lo...   \n",
       "32     33                          bitch retarded  hate @url   \n",
       "33     34                                  @user migrants.7z   \n",
       "34     35  hetero guy: faggot bet wanna suck dick nnme: @url   \n",
       "35     36                @user fallait pad arriver en retard   \n",
       "36     37  using word retard form great way make lose hug...   \n",
       "37     38  everyone knows feminazi's r lying gd teeth @us...   \n",
       "38     39  @user care moral voters; want liberals illegal...   \n",
       "39     40  @user still bitter cunt. much interest arsenal...   \n",
       "\n",
       "                                         sentiment directness  \\\n",
       "0                                        offensive   indirect   \n",
       "1                          offensive_disrespectful   indirect   \n",
       "2                fearful_abusive_offensive_hateful   indirect   \n",
       "3     fearful_abusive_hateful_disrespectful_normal   indirect   \n",
       "4                                        offensive   indirect   \n",
       "5                                        offensive   indirect   \n",
       "6                                        offensive   indirect   \n",
       "7                                        offensive   indirect   \n",
       "8                                        offensive   indirect   \n",
       "9                                        offensive   indirect   \n",
       "10                                       offensive   indirect   \n",
       "11                                       offensive     direct   \n",
       "12                                       offensive   indirect   \n",
       "13                                       offensive   indirect   \n",
       "14                                       offensive   indirect   \n",
       "15                                          normal   indirect   \n",
       "16                               offensive_hateful     direct   \n",
       "17                           hateful_disrespectful   indirect   \n",
       "18                                       offensive   indirect   \n",
       "19                                          normal   indirect   \n",
       "20                           hateful_disrespectful   indirect   \n",
       "21                                       offensive   indirect   \n",
       "22                                  hateful_normal   indirect   \n",
       "23                                       offensive   indirect   \n",
       "24                                         hateful     direct   \n",
       "25                                       offensive   indirect   \n",
       "26                                       offensive   indirect   \n",
       "27                               abusive_offensive     direct   \n",
       "28                                       offensive   indirect   \n",
       "29                                          normal   indirect   \n",
       "30                                       offensive   indirect   \n",
       "31                                       offensive   indirect   \n",
       "32                                       offensive   indirect   \n",
       "33                                  abusive_normal   indirect   \n",
       "34                                offensive_normal   indirect   \n",
       "35  abusive_offensive_hateful_disrespectful_normal   indirect   \n",
       "36  fearful_offensive_hateful_disrespectful_normal   indirect   \n",
       "37                                       offensive   indirect   \n",
       "38                                       offensive   indirect   \n",
       "39                                 abusive_hateful   indirect   \n",
       "\n",
       "                            annotator_sentiment              target  \\\n",
       "0                             confusion_disgust              origin   \n",
       "1                               anger_confusion          disability   \n",
       "2                             confusion_disgust          disability   \n",
       "3              anger_fear_shock_sadness_disgust              origin   \n",
       "4                                 shock_disgust              gender   \n",
       "5                                 anger_sadness              origin   \n",
       "6        confusion_sadness_indifference_disgust              origin   \n",
       "7   confusion_fear_indifference_sadness_disgust  sexual_orientation   \n",
       "8       anger_fear_indifference_sadness_disgust              origin   \n",
       "9                          sadness_indifference          disability   \n",
       "10                       confusion_indifference              origin   \n",
       "11                       confusion_indifference  sexual_orientation   \n",
       "12                                shock_disgust  sexual_orientation   \n",
       "13                                shock_disgust              origin   \n",
       "14         confusion_fear_shock_sadness_disgust               other   \n",
       "15                                shock_disgust              origin   \n",
       "16                                shock_disgust          disability   \n",
       "17                                shock_disgust              origin   \n",
       "18                       confusion_indifference  sexual_orientation   \n",
       "19                                anger_sadness               other   \n",
       "20           sadness_shock_indifference_disgust              gender   \n",
       "21                       confusion_indifference               other   \n",
       "22                                shock_disgust              origin   \n",
       "23                                anger_sadness          disability   \n",
       "24                         indifference_disgust              origin   \n",
       "25                       confusion_indifference              origin   \n",
       "26                                anger_sadness               other   \n",
       "27                                anger_disgust              gender   \n",
       "28                              sadness_disgust              origin   \n",
       "29                                anger_sadness              origin   \n",
       "30                            confusion_disgust              origin   \n",
       "31                       confusion_indifference              origin   \n",
       "32                                anger_sadness          disability   \n",
       "33                           shock_indifference              origin   \n",
       "34                         indifference_disgust  sexual_orientation   \n",
       "35                         indifference_disgust          disability   \n",
       "36                                shock_disgust  sexual_orientation   \n",
       "37                         indifference_disgust               other   \n",
       "38                         indifference_disgust               other   \n",
       "39                                anger_sadness              gender   \n",
       "\n",
       "               group  predictions  \n",
       "0                gay            2  \n",
       "1      special_needs            2  \n",
       "2      special_needs            2  \n",
       "3              other            2  \n",
       "4              women            2  \n",
       "5   left_wing_people            2  \n",
       "6              other            2  \n",
       "7              other            2  \n",
       "8      special_needs            2  \n",
       "9      special_needs            2  \n",
       "10             other            2  \n",
       "11        individual            2  \n",
       "12             women            2  \n",
       "13        immigrants            2  \n",
       "14             other            2  \n",
       "15             other            1  \n",
       "16     special_needs            2  \n",
       "17             other            2  \n",
       "18             other            2  \n",
       "19             other            0  \n",
       "20             women            2  \n",
       "21             other            2  \n",
       "22             other            2  \n",
       "23     special_needs            2  \n",
       "24        individual            2  \n",
       "25        immigrants            2  \n",
       "26             other            2  \n",
       "27             women            2  \n",
       "28             other            2  \n",
       "29             other            2  \n",
       "30     special_needs            0  \n",
       "31     special_needs            2  \n",
       "32             women            2  \n",
       "33             other            2  \n",
       "34             other            2  \n",
       "35     special_needs            0  \n",
       "36             other            2  \n",
       "37             women            2  \n",
       "38             other            2  \n",
       "39             women            2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One by One\n",
    "\n",
    "used_data = en_dataset.iloc[0:40]\n",
    "predictions_concat=[]\n",
    "\n",
    "# Wrap range with tqdm\n",
    "for i in tqdm(range(used_data.shape[0])):\n",
    "    tweet = en_dataset['tweet'].iloc[i]\n",
    "    # prompt\n",
    "    prompt = [{\"role\": \"system\", \"content\": \"Do you think these tweets are hate speech, offensive or normal speech. Try your best even if we do not have context. Display the reasult as an integer of 0 (Normal), 1 (offensive) and 2 (hate). Do not display anything else, it is important that only the interger is displayed.\"},\n",
    "              {\"role\": \"user\", \"content\": tweet},]\n",
    "    # LLM initialization\n",
    "    llm = Ollama(model=\"llama3\")\n",
    "    predictions = llm.invoke(prompt)\n",
    "    predictions = int(predictions) \n",
    "    predictions_concat.append(predictions)\n",
    "\n",
    "print(len(predictions_concat))\n",
    "#add the predictions to the dataset\n",
    "used_data['predictions'] = predictions_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m      4\u001b[0m acc\u001b[38;5;241m=\u001b[39maccuracy_score(used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m], used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m F1\u001b[38;5;241m=\u001b[39m\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m Precision\u001b[38;5;241m=\u001b[39mprecision_score(used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m], used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m], average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m Recall\u001b[38;5;241m=\u001b[39mrecall_score(used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m], used_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m], average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1271\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1092\u001b[0m     {\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1119\u001b[0m ):\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1463\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1284\u001b[0m     {\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1313\u001b[0m ):\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1767\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m \n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1767\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1542\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1539\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m-> 1542\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.12/site-packages/sklearn/utils/multiclass.py:116\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "#Metrics\n",
    "acc=accuracy_score(used_data['sentiment'], used_data['predictions'])\n",
    "F1=f1_score(used_data['sentiment'], used_data['predictions'], average='macro')\n",
    "Precision=precision_score(used_data['sentiment'], used_data['predictions'], average='macro')\n",
    "Recall=recall_score(used_data['sentiment'], used_data['predictions'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
